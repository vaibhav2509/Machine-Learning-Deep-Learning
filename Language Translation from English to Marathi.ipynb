{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "\n",
    "no_of_inputs = 25000\n",
    "count = 0\n",
    "\n",
    "for line in open(r'C:\\Users\\Vamishra\\Downloads\\mar-eng\\mar.txt', encoding=\"utf-8\"):\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    inp = line.rstrip().split('\\t')[0]\n",
    "    out = line.rstrip().split('\\t')[1]\n",
    "    \n",
    "    input_sentences.append(inp)\n",
    "    output_sentences.append(out)\n",
    "    \n",
    "    if count > no_of_inputs:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't call me.  ---->  मला कॉल नको करूस.\n",
      "That's about it.  ---->  तेवढंच.\n",
      "Was I snoring?  ---->  मी घोरत होतो का?\n",
      "I'm in Perth.  ---->  मी पर्थमध्ये आहे.\n",
      "Tom was working for me.  ---->  टॉम माझ्यासाठी काम करत होता.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    j = np.random.choice(no_of_inputs)\n",
    "    print(input_sentences[j] + \"  ---->  \" + output_sentences[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_decoder_sentences = []\n",
    "output_decoder_sentences = []\n",
    "\n",
    "for i in range(len(output_sentences)):\n",
    "    inp_dec_sent = 'sos ' + output_sentences[i]\n",
    "    input_decoder_sentences.append(inp_dec_sent)\n",
    "    out_dec_sent = output_sentences[i] + ' eos'\n",
    "    output_decoder_sentences.append(out_dec_sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['पळ! eos', 'धाव! eos', 'पळा! eos', 'धावा! eos']\n",
      "['sos पळ!', 'sos धाव!', 'sos पळा!', 'sos धावा!']\n"
     ]
    }
   ],
   "source": [
    "print(output_decoder_sentences[1:5])\n",
    "print(input_decoder_sentences[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vamishra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input , Embedding , LSTM , Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = Tokenizer()\n",
    "encoder_tokens.fit_on_texts(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2idx = encoder_tokens.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_sentences = encoder_tokens.texts_to_sequences(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_tokens = Tokenizer()\n",
    "decoder_tokens.fit_on_texts(input_decoder_sentences + output_decoder_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathi_word2idx = decoder_tokens.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_decoder_sentences = decoder_tokens.texts_to_sequences(input_decoder_sentences)\n",
    "output_decoder_sentences = decoder_tokens.texts_to_sequences(output_decoder_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "max_input_length = max(len(sen) for sen in input_encoder_sentences)\n",
    "max_output_length = max(len(sen) for sen in output_decoder_sentences)\n",
    "print(max_input_length)\n",
    "print(max_output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_sentences = pad_sequences(input_encoder_sentences , maxlen=max_input_length , padding='pre')\n",
    "input_decoder_sentences = pad_sequences(input_decoder_sentences , maxlen=max_output_length , padding='post')\n",
    "output_decoder_sentences = pad_sequences(output_decoder_sentences , maxlen=max_output_length , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(eng_word2idx) + 1\n",
    "marathi_vocab_size = len(marathi_word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_output_decoder_tokens = np.zeros((len(output_decoder_sentences) , max_output_length , marathi_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , j in enumerate(output_decoder_sentences):\n",
    "    for k , word in enumerate(j):\n",
    "        one_hot_output_decoder_tokens[i , k , word] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0 179  11]]\n",
      "[[  1   6 478   0   0   0   0   0   0   0   0]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(input_encoder_sentences[103:104])\n",
    "print(input_decoder_sentences[103:104])\n",
    "print(one_hot_output_decoder_tokens[103:104][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 8, 100)       359300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 11, 100)      775300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30), (None,  15720       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 11, 30), (No 15720       embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 11, 7753)     240343      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,406,383\n",
      "Trainable params: 1,406,383\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building up the model\n",
    "\n",
    "Embedding_length = 100\n",
    "lstm_unit = 30\n",
    "\n",
    "encoding_input = Input(batch_shape=(None , max_input_length))\n",
    "\n",
    "encoding_embedding = Embedding(english_vocab_size , Embedding_length , input_length=max_input_length)\n",
    "\n",
    "embedding_out_encode = encoding_embedding(encoding_input)\n",
    "\n",
    "encoding_lstm = LSTM(lstm_unit , return_state=True)\n",
    "\n",
    "_ , state_h , state_c = encoding_lstm(embedding_out_encode)\n",
    "\n",
    "\n",
    "states = [state_h , state_c]\n",
    "\n",
    "decoding_input = Input(batch_shape=(None , max_output_length))\n",
    "\n",
    "decoding_embedding = Embedding(marathi_vocab_size , Embedding_length)\n",
    "\n",
    "embedding_out_decode = decoding_embedding(decoding_input)\n",
    "\n",
    "decoding_lstm = LSTM(lstm_unit , return_sequences=True , return_state=True)\n",
    "\n",
    "decoding_output , _ , _ = decoding_lstm(embedding_out_decode , initial_state=states)\n",
    "\n",
    "decoding_dense = Dense(marathi_vocab_size , activation='softmax')\n",
    "\n",
    "decoding_output = decoding_dense(decoding_output)\n",
    "\n",
    "seq2seq_model = Model([encoding_input , decoding_input] , decoding_output)\n",
    "\n",
    "seq2seq_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model.compile(optimizer='rmsprop' , loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vamishra\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Vamishra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 20000 samples, validate on 5001 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 162s 8ms/step - loss: 6.1812 - accuracy: 0.5579 - val_loss: 4.5930 - val_accuracy: 0.4808\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 161s 8ms/step - loss: 3.2941 - accuracy: 0.5633 - val_loss: 3.5229 - val_accuracy: 0.4808\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 164s 8ms/step - loss: 2.6307 - accuracy: 0.5662 - val_loss: 3.1937 - val_accuracy: 0.4996\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 162s 8ms/step - loss: 2.3527 - accuracy: 0.6427 - val_loss: 3.0079 - val_accuracy: 0.5850\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 160s 8ms/step - loss: 2.1988 - accuracy: 0.6678 - val_loss: 2.9433 - val_accuracy: 0.5863\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 168s 8ms/step - loss: 2.1093 - accuracy: 0.6733 - val_loss: 2.8812 - val_accuracy: 0.5944\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 163s 8ms/step - loss: 2.0423 - accuracy: 0.6838 - val_loss: 2.8292 - val_accuracy: 0.6052\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 161s 8ms/step - loss: 1.9889 - accuracy: 0.6908 - val_loss: 2.8028 - val_accuracy: 0.6094\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 162s 8ms/step - loss: 1.9407 - accuracy: 0.6956 - val_loss: 2.7642 - val_accuracy: 0.6135\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 168s 8ms/step - loss: 1.8949 - accuracy: 0.7005 - val_loss: 2.7493 - val_accuracy: 0.6153\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 158s 8ms/step - loss: 1.8504 - accuracy: 0.7057 - val_loss: 2.7133 - val_accuracy: 0.6200\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 152s 8ms/step - loss: 1.8066 - accuracy: 0.7119 - val_loss: 2.6909 - val_accuracy: 0.6232\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 159s 8ms/step - loss: 1.7631 - accuracy: 0.7177 - val_loss: 2.6534 - val_accuracy: 0.6275\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 162s 8ms/step - loss: 1.7200 - accuracy: 0.7231 - val_loss: 2.6368 - val_accuracy: 0.6313\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 149s 7ms/step - loss: 1.6793 - accuracy: 0.7287 - val_loss: 2.6052 - val_accuracy: 0.6343\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 164s 8ms/step - loss: 1.6407 - accuracy: 0.7332 - val_loss: 2.5784 - val_accuracy: 0.6368\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 157s 8ms/step - loss: 1.6039 - accuracy: 0.7377 - val_loss: 2.5644 - val_accuracy: 0.6391\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 176s 9ms/step - loss: 1.5688 - accuracy: 0.7419 - val_loss: 2.5374 - val_accuracy: 0.6418\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 170s 8ms/step - loss: 1.5353 - accuracy: 0.7463 - val_loss: 2.5217 - val_accuracy: 0.6439\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 187s 9ms/step - loss: 1.5030 - accuracy: 0.7504 - val_loss: 2.5052 - val_accuracy: 0.6463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f9147304e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_model.fit([input_encoder_sentences , input_decoder_sentences] , one_hot_output_decoder_tokens , epochs=20 , batch_size=200 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model.save(r'C:\\Users\\Vamishra\\Downloads\\mar-eng\\english_to_marathi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 8, 100)            359300    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 30), (None, 30),  15720     \n",
      "=================================================================\n",
      "Total params: 375,020\n",
      "Trainable params: 375,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (1, 1)               0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         multiple             775300      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   multiple             15720       embedding_2[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 multiple             240343      lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,031,363\n",
      "Trainable params: 1,031,363\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating inference model\n",
    "\n",
    "encoding_inference = Model(encoding_input , states)\n",
    "\n",
    "decoder_input_hidden_state = Input(batch_shape=(None , lstm_unit))\n",
    "decoder_input_cell_state = Input(batch_shape=(None , lstm_unit))\n",
    "\n",
    "decoder_input_states = [decoder_input_hidden_state , decoder_input_cell_state]\n",
    "\n",
    "single_input = Input(batch_shape=(1,1))\n",
    "\n",
    "single_embedding_output = decoding_embedding(single_input)\n",
    "\n",
    "single_decoder_output , decoder_h_state , decoder_c_state = decoding_lstm(single_embedding_output , initial_state = decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h_state , decoder_c_state]\n",
    "\n",
    "single_decoder_output = decoding_dense(single_decoder_output)\n",
    "\n",
    "decoding_inference = Model([single_input] + decoder_input_states , [single_decoder_output] + decoder_states)\n",
    "\n",
    "encoding_inference.summary()\n",
    "\n",
    "decoding_inference.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_idx2word = {j : i for i , j in eng_word2idx.items()}\n",
    "marathi_idx2word = {j : i for i,j in marathi_word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(seq):\n",
    "    \n",
    "    states = encoding_inference.predict(seq)\n",
    "    \n",
    "    single_inp = np.zeros((1,1))\n",
    "    \n",
    "    single_inp[0,0] = marathi_word2idx['sos']\n",
    "    \n",
    "    eos_idx = marathi_word2idx['eos']\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    for _ in range(max_output_length):\n",
    "        \n",
    "        output , h , c = decoding_inference.predict([single_inp] + states)\n",
    "        \n",
    "        index = np.argmax(output[0,0,:])\n",
    "        \n",
    "        if index == eos_idx:\n",
    "            break\n",
    "        if index > 0:\n",
    "            word = marathi_idx2word[index]\n",
    "            \n",
    "            sentence.append(word)\n",
    "        \n",
    "        states = [h , c]\n",
    "        \n",
    "        single_inp[0,0] = index\n",
    "        \n",
    "    return ' '.join(sentence)     \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_translate(seq):\n",
    "    \n",
    "    states = encoding_inference.predict(seq)\n",
    "    \n",
    "    single_inp = np.zeros((1,1))\n",
    "    \n",
    "    single_inp[0,0] = marathi_word2idx['sos']\n",
    "    \n",
    "    end_idx = marathi_word2idx['eos']\n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(len(max_output_length)):\n",
    "        \n",
    "        output , h , c = decoding_inference.predict([single_inp] + states)\n",
    "        \n",
    "        decoder_state = [h ,c]\n",
    "        \n",
    "        beam_idx = np.argsort(output[0,0,:])[::-1][0:k]\n",
    "        \n",
    "        if beam_idx[0] == end_idx:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            for i in beam_idx:\n",
    "                if i != end_idx and i > 0:\n",
    "                    single_inp[0,0] = i\n",
    "                    output , h , c = decoding_inference.predict([single_inp] + decoder_state)\n",
    "                    \n",
    "                    next_beam_idx = np.argsort(output[0,0,:])[::-1][0:k]\n",
    "                    \n",
    "                    result_beam = [i*j for j in next_beam_idx]\n",
    "            \n",
    "        \n",
    "        # applying beam search \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English Sentence-->   Do you know her?\n",
      "Original Marathi Sentence-->   तुम्ही त्यांना ओळखता का?\n",
      "Predicted Marathi Sentence->   तू तुला करू शकत नाही\n",
      "\n",
      "Original English Sentence-->   Tom calls Mary every night.\n",
      "Original Marathi Sentence-->   टॉम मेरीला दर रात्री फोन करतो.\n",
      "Predicted Marathi Sentence->   टॉम टॉमला मेरीला पाहिलं\n",
      "\n",
      "Original English Sentence-->   Where exactly do you live?\n",
      "Original Marathi Sentence-->   तू नक्की कुठे राहतेस?\n",
      "Predicted Marathi Sentence->   तू तू सर्व आहेस\n",
      "\n",
      "Original English Sentence-->   That day shall come.\n",
      "Original Marathi Sentence-->   तो दिवस येईलच.\n",
      "Predicted Marathi Sentence->   ते बंद कर\n",
      "\n",
      "Original English Sentence-->   I am hers and she is mine.\n",
      "Original Marathi Sentence-->   मी तिचा आहे व ती माझी.\n",
      "Predicted Marathi Sentence->   मी माझ्या माझ्या फ्रेंच आहेत\n",
      "\n",
      "Original English Sentence-->   I'm just pulling your leg.\n",
      "Original Marathi Sentence-->   मी फक्त तुम्हाला शेंडी लावतेय.\n",
      "Predicted Marathi Sentence->   मी माझ्या तीन आहेत\n",
      "\n",
      "Original English Sentence-->   He'll understand.\n",
      "Original Marathi Sentence-->   तो समजून घेईल.\n",
      "Predicted Marathi Sentence->   ते\n",
      "\n",
      "Original English Sentence-->   They named their dog Lucky.\n",
      "Original Marathi Sentence-->   त्यांनी त्यांच्या कुत्र्याचं नाव \"लकी\" ठेवलं.\n",
      "Predicted Marathi Sentence->   तो तो एक तीन आहेत\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(8):\n",
    "    \n",
    "    i = np.random.choice(count)\n",
    "    print(\"Original English Sentence-->   \" + input_sentences[i])\n",
    "    print(\"Original Marathi Sentence-->   \" + output_sentences[i])\n",
    "    print(\"Predicted Marathi Sentence->   \" + translate(input_encoder_sentences[i:i+1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.42919114, -0.5411559 ,  0.46467945,  0.54558647, -0.505681  ,\n",
       "          0.20195134,  0.19051859, -0.5422826 ,  0.30926082, -0.21427141,\n",
       "         -0.00933504,  0.17363161, -0.2696954 ,  0.6471846 ,  0.40152815,\n",
       "         -0.36944485,  0.37207875, -0.35169792, -0.5144791 ,  0.09291419,\n",
       "          0.64537376,  0.6986939 ,  0.26117864,  0.56891596,  0.4500186 ,\n",
       "         -0.54126036, -0.03436617, -0.02845625,  0.06511852,  0.22114035]],\n",
       "       dtype=float32),\n",
       " array([[ 1.0097774 , -1.7419832 ,  0.8279504 ,  0.7365363 , -2.0253334 ,\n",
       "          0.39094418,  0.71535456, -0.64492214,  0.5456326 , -0.38805428,\n",
       "         -0.01888308,  0.31767637, -0.518613  ,  2.6515179 ,  0.6064822 ,\n",
       "         -0.75984985,  0.84434354, -1.0195284 , -1.4014621 ,  0.10922215,\n",
       "          1.2187359 ,  1.7618781 ,  0.35226548,  2.5945852 ,  4.048413  ,\n",
       "         -3.2336683 , -0.06994502, -0.07574804,  0.1498369 ,  0.3013489 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_inference.predict(input_encoder_sentences[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
