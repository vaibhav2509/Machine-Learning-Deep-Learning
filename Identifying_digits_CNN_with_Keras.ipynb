{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "# Numpy for storing the Image as a matrix\n",
    "# pandas to import the output csv file\n",
    "# openCV (i.e cv2) for importing the images\n",
    "# matplotlib for visualization\n",
    "# glob to access the folder in which the images are stored\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"D:\\self learning\\Machine_Learning_AZ_Template_Folder\\Machine Learning A-Z Template Folder\\Part 8 - Deep Learning\\Section 40 - Convolutional Neural Networks (CNN)\\Train\\Images\\train\\0.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b584f230f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b582e7e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"D:\\self learning\\Machine_Learning_AZ_Template_Folder\\Machine Learning A-Z Template Folder\\Part 8 - Deep Learning\\Section 40 - Convolutional Neural Networks (CNN)\\Train\\Images\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing image from folder into Notebook\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in glob.glob(r\"D:\\self learning\\Machine_Learning_AZ_Template_Folder\\Machine Learning A-Z Template Folder\\Part 8 - Deep Learning\\Section 40 - Convolutional Neural Networks (CNN)\\Train\\Images\\train\\*.png\"):\n",
    "    img2 = cv2.imread(i)\n",
    "    #img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    images.append(img2)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the image to numpy matrix\n",
    "\n",
    "X = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ..., \n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the pixel values from 0-255 to 0-1\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the csv contaning the output of the images\n",
    "\n",
    "labels = pd.read_csv(r\"D:\\self learning\\Machine_Learning_AZ_Template_Folder\\Machine Learning A-Z Template Folder\\Part 8 - Deep Learning\\Section 40 - Convolutional Neural Networks (CNN)\\Train\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = labels['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding the output variable\n",
    "\n",
    "y = pd.get_dummies(labels , columns = ['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping the numpy matrix of the image\n",
    "\n",
    "X = X.reshape(49000 , 28,28,3).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  0  0  0  0  1  0  0  0  0  0\n",
       "1  0  0  0  0  0  0  0  0  0  1\n",
       "2  0  1  0  0  0  0  0  0  0  0\n",
       "3  0  0  0  0  0  0  0  1  0  0\n",
       "4  0  0  0  1  0  0  0  0  0  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining train and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Defing the models used to develop the neural network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D , Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequntial() funtion to define the neural net\n",
    "# Adding the convolution layer(i.e Feature Map , 32 in number with 4*4 size) and activation function as relu\n",
    "# Adding MaxPooling layer , which converts each Feature map defined above of size 4*4 to 2*2 (but 32 in number still)\n",
    "# Dropout to drop the features which contains less than 20% of the information\n",
    "# Flatten to convert the 32 feature map of 2*2 into 1D array(which corresponds to 128 as 32*2*2 = 128)\n",
    "# Adding Dense layer(Input layer of ANN) with 128 input neurons in the first layer and relu as the activation function\n",
    "# Adding second Dense layer of 10 Neurons( Number of classification) as the output layer\n",
    "# Softmax as the activation function in the output layer for a multi classification problem\n",
    "# If the classification was for 2 outputs only , sigmoid would have been used as the output activation function\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (4, 4), input_shape=(28, 28 , 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/40\n",
      " - 27s - loss: 0.4793 - acc: 0.8355 - val_loss: 5.6993 - val_acc: 0.0952\n",
      "Epoch 2/40\n",
      " - 28s - loss: 0.4809 - acc: 0.8354 - val_loss: 5.7115 - val_acc: 0.0989\n",
      "Epoch 3/40\n",
      " - 26s - loss: 0.4818 - acc: 0.8371 - val_loss: 5.7011 - val_acc: 0.0996\n",
      "Epoch 4/40\n",
      " - 27s - loss: 0.4726 - acc: 0.8397 - val_loss: 5.7488 - val_acc: 0.1003\n",
      "Epoch 5/40\n",
      " - 28s - loss: 0.4581 - acc: 0.8438 - val_loss: 5.8168 - val_acc: 0.0976\n",
      "Epoch 6/40\n",
      " - 28s - loss: 0.4522 - acc: 0.8472 - val_loss: 5.8255 - val_acc: 0.0999\n",
      "Epoch 7/40\n",
      " - 30s - loss: 0.4567 - acc: 0.8441 - val_loss: 5.8795 - val_acc: 0.1005\n",
      "Epoch 8/40\n",
      " - 29s - loss: 0.4550 - acc: 0.8464 - val_loss: 5.8815 - val_acc: 0.1009\n",
      "Epoch 9/40\n",
      " - 28s - loss: 0.4414 - acc: 0.8468 - val_loss: 5.9415 - val_acc: 0.0997\n",
      "Epoch 10/40\n",
      " - 29s - loss: 0.4400 - acc: 0.8513 - val_loss: 5.9584 - val_acc: 0.1004\n",
      "Epoch 11/40\n",
      " - 28s - loss: 0.4314 - acc: 0.8530 - val_loss: 6.0217 - val_acc: 0.1018\n",
      "Epoch 12/40\n",
      " - 28s - loss: 0.4458 - acc: 0.8468 - val_loss: 5.9230 - val_acc: 0.0988\n",
      "Epoch 13/40\n",
      " - 28s - loss: 0.4221 - acc: 0.8576 - val_loss: 6.0152 - val_acc: 0.0980\n",
      "Epoch 14/40\n",
      " - 29s - loss: 0.4389 - acc: 0.8519 - val_loss: 6.0088 - val_acc: 0.1008\n",
      "Epoch 15/40\n",
      " - 28s - loss: 0.4192 - acc: 0.8586 - val_loss: 6.0242 - val_acc: 0.0998\n",
      "Epoch 16/40\n",
      " - 27s - loss: 0.4170 - acc: 0.8578 - val_loss: 6.0839 - val_acc: 0.0997\n",
      "Epoch 17/40\n",
      " - 28s - loss: 0.4101 - acc: 0.8598 - val_loss: 6.1478 - val_acc: 0.1006\n",
      "Epoch 18/40\n",
      " - 27s - loss: 0.4174 - acc: 0.8585 - val_loss: 6.1102 - val_acc: 0.1017\n",
      "Epoch 19/40\n",
      " - 28s - loss: 0.4098 - acc: 0.8616 - val_loss: 6.2150 - val_acc: 0.0974\n",
      "Epoch 20/40\n",
      " - 26s - loss: 0.4036 - acc: 0.8640 - val_loss: 6.2084 - val_acc: 0.0986\n",
      "Epoch 21/40\n",
      " - 27s - loss: 0.3969 - acc: 0.8646 - val_loss: 6.2378 - val_acc: 0.0978\n",
      "Epoch 22/40\n",
      " - 29s - loss: 0.3996 - acc: 0.8642 - val_loss: 6.2233 - val_acc: 0.0968\n",
      "Epoch 23/40\n",
      " - 29s - loss: 0.3922 - acc: 0.8673 - val_loss: 6.2499 - val_acc: 0.1003\n",
      "Epoch 24/40\n",
      " - 32s - loss: 0.3911 - acc: 0.8675 - val_loss: 6.2780 - val_acc: 0.0972\n",
      "Epoch 25/40\n",
      " - 28s - loss: 0.3869 - acc: 0.8679 - val_loss: 6.3577 - val_acc: 0.0998\n",
      "Epoch 26/40\n",
      " - 28s - loss: 0.3830 - acc: 0.8708 - val_loss: 6.3703 - val_acc: 0.0977\n",
      "Epoch 27/40\n",
      " - 27s - loss: 0.3817 - acc: 0.8711 - val_loss: 6.4067 - val_acc: 0.0989\n",
      "Epoch 28/40\n",
      " - 27s - loss: 0.3805 - acc: 0.8714 - val_loss: 6.4035 - val_acc: 0.1003\n",
      "Epoch 29/40\n",
      " - 26s - loss: 0.3749 - acc: 0.8736 - val_loss: 6.3953 - val_acc: 0.1005\n",
      "Epoch 30/40\n",
      " - 27s - loss: 0.3685 - acc: 0.8737 - val_loss: 6.4650 - val_acc: 0.0989\n",
      "Epoch 31/40\n",
      " - 27s - loss: 0.3743 - acc: 0.8728 - val_loss: 6.4305 - val_acc: 0.1012\n",
      "Epoch 32/40\n",
      " - 26s - loss: 0.3701 - acc: 0.8735 - val_loss: 6.4628 - val_acc: 0.1011\n",
      "Epoch 33/40\n",
      " - 27s - loss: 0.3650 - acc: 0.8765 - val_loss: 6.4938 - val_acc: 0.0994\n",
      "Epoch 34/40\n",
      " - 27s - loss: 0.3599 - acc: 0.8784 - val_loss: 6.5005 - val_acc: 0.0995\n",
      "Epoch 35/40\n",
      " - 26s - loss: 0.3600 - acc: 0.8771 - val_loss: 6.5428 - val_acc: 0.1031\n",
      "Epoch 36/40\n",
      " - 26s - loss: 0.3532 - acc: 0.8792 - val_loss: 6.5854 - val_acc: 0.0969\n",
      "Epoch 37/40\n",
      " - 27s - loss: 0.3495 - acc: 0.8825 - val_loss: 6.5982 - val_acc: 0.0991\n",
      "Epoch 38/40\n",
      " - 27s - loss: 0.3566 - acc: 0.8797 - val_loss: 6.5620 - val_acc: 0.0997\n",
      "Epoch 39/40\n",
      " - 27s - loss: 0.3459 - acc: 0.8823 - val_loss: 6.6151 - val_acc: 0.0983\n",
      "Epoch 40/40\n",
      " - 26s - loss: 0.3533 - acc: 0.8811 - val_loss: 6.6468 - val_acc: 0.0982\n",
      "9800/9800 [==============================] - 3s 279us/step\n",
      "CNN Error: 90.18%\n"
     ]
    }
   ],
   "source": [
    "# Fitting the neural net defined above with the training data\n",
    "\n",
    "model.fit(X_train , y_train ,validation_data=(X_test, y_test) , epochs=40 , batch_size=200 , verbose=2)\n",
    "result = model.evaluate(X_test , y_test)\n",
    "print(\"CNN Error: %.2f%%\" % (100-result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
